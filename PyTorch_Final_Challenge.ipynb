{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch Final Challenge.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "KCWx_60eof_T",
        "colab_type": "code",
        "outputId": "2db9f160-0bdb-441d-d5e6-2d96555f23ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install torch\n",
        "!pip install torchvision"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (0.4.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.2.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.6)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision) (0.4.1)\n",
            "Collecting pillow>=4.1.1 (from torchvision)\n",
            "  Using cached https://files.pythonhosted.org/packages/62/94/5430ebaa83f91cc7a9f687ff5238e26164a779cca2ef9903232268b0a318/Pillow-5.3.0-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n",
            "Installing collected packages: pillow\n",
            "  Found existing installation: Pillow 4.0.0\n",
            "    Uninstalling Pillow-4.0.0:\n",
            "      Successfully uninstalled Pillow-4.0.0\n",
            "Successfully installed pillow-5.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "T2gOC6eKorg_",
        "colab_type": "code",
        "outputId": "2c30c796-417c-448f-861d-b67fd9cd82d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms, datasets\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "#import \n",
        "print('Done')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RjqeNloEorkm",
        "colab_type": "code",
        "outputId": "d8053bcd-284c-4c14-a883-2c7bc160637c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "data_transform = transforms.Compose([\n",
        "    #transforms.CenterCrop(500),\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    #transforms.Resize(224),\n",
        "    transforms.RandomHorizontalFlip(p=0.4),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485,0.456,0.4406], std=[0.229,0.224,0.225])\n",
        "])\n",
        "\n",
        "\n",
        "'''\n",
        "\n",
        "data_transform = transforms.Compose([\n",
        "    transforms.RandomSizedCrop(224),\n",
        "    transforms.Resize(224),\n",
        "    transforms.CenterCrop(500),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
        "'''\n",
        "\n",
        "data_transform"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Compose(\n",
              "    RandomResizedCrop(size=(224, 224), scale=(0.08, 1.0), ratio=(0.75, 1.3333), interpolation=PIL.Image.BILINEAR)\n",
              "    RandomHorizontalFlip(p=0.4)\n",
              "    ToTensor()\n",
              "    Normalize(mean=[0.485, 0.456, 0.4406], std=[0.229, 0.224, 0.225])\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "UI-9kbQp4zfA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#!pip install requests"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kZU52Kxe6IQH",
        "colab_type": "code",
        "outputId": "7759085c-203a-435b-96c0-0eda3c96f2dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import requests, zipfile, io\n",
        "\n",
        "r = requests.get('https://s3.amazonaws.com/content.udacity-data.com/courses/nd188/flower_data.zip')\n",
        "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
        "z.extractall()\n",
        "\n",
        "print('Done')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "54ZXLMj-oru3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data_dir = './flower_data/'\n",
        "train_dir = os.path.join(data_dir, 'train/') \n",
        "test_dir = os.path.join(data_dir, 'valid/') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LULbnSsUor0J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Loading images and creating labels\n",
        "\n",
        "train_data = datasets.ImageFolder(train_dir, transform = data_transform) \n",
        "test_data = datasets.ImageFolder(test_dir, transform = data_transform) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TD6bw2O7or9_",
        "colab_type": "code",
        "outputId": "b0a44bdb-d534-47d9-bdab-b796a796f471",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "print('No of training images', len(train_data))\n",
        "print('No of testing images', len(test_data))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No of training images 6552\n",
            "No of testing images 818\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oUVW9jR8osSc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load the data\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=100, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=100, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2q18e39WJXWQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Bigo4r1losad",
        "colab_type": "code",
        "outputId": "980b4156-be4c-4392-d498-6718294dd3c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1445
        }
      },
      "cell_type": "code",
      "source": [
        "# Load pre-train model\n",
        "\n",
        "model = torchvision.models.resnet18(pretrained=True)\n",
        "model"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
              "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "SERSLDzxosiw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Reset Gradient\n",
        "\n",
        "for param in model.parameters():\n",
        "  param.requires_grad = False  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LRi4XbtBospJ",
        "colab_type": "code",
        "outputId": "165ea279-43b8-4d33-f034-9dff42bcbcf1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# getting the no.of neurons in last layers\n",
        "\n",
        "num_features = model.fc.in_features\n",
        "num_features"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "512"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "YiDsWq1qosuR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class PSC(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(PSC, self).__init__()\n",
        "    self.fc1 = nn.Linear(in_features = num_features, out_features=256)\n",
        "    self.dropout = nn.Dropout(0.25)\n",
        "    self.fc2 = nn.Linear(in_features = 256, out_features=64)\n",
        "    self.fc3 = nn.Linear(in_features = 64, out_features=256)\n",
        "    self.fc4 = nn.Linear(in_features = 256, out_features=102)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = self.dropout(x)\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = F.relu(self.fc3(x))\n",
        "    x = self.fc4(x)\n",
        "    return x\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0ghQd4Lsosyz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.fc = PSC()\n",
        "#model.load_state_dict(torch.load('PreTrainV01.pt'), strict=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5SQGB8R-os3R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Define Loss and Optimizer\n",
        "\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001 )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8iiV5ErJLLcM",
        "colab_type": "code",
        "outputId": "8959e049-0661-4647-abed-59c31aa6cdc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "examples = enumerate(train_loader)\n",
        "for (a,b) in examples:\n",
        "  print(a)\n",
        "  \n",
        "'''"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nexamples = enumerate(train_loader)\\nfor (a,b) in examples:\\n  print(a)\\n  \\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "X304E7eVO30V",
        "colab_type": "code",
        "outputId": "52cdbe8c-e376-45a5-b787-90c15a9f3f04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install Pillow==4.0.0\n",
        "!pip install PIL\n",
        "!pip install image\n",
        "\n",
        "#from PIL import Im"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting Pillow==4.0.0\n",
            "  Using cached https://files.pythonhosted.org/packages/37/e8/b3fbf87b0188d22246678f8cd61e23e31caa1769ebc06f1664e2e5fe8a17/Pillow-4.0.0-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow==4.0.0) (0.46)\n",
            "\u001b[31mtorchvision 0.2.1 has requirement pillow>=4.1.1, but you'll have pillow 4.0.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: Pillow\n",
            "  Found existing installation: Pillow 5.3.0\n",
            "    Uninstalling Pillow-5.3.0:\n",
            "      Successfully uninstalled Pillow-5.3.0\n",
            "Successfully installed Pillow-4.0.0\n",
            "Collecting PIL\n",
            "\u001b[31m  Could not find a version that satisfies the requirement PIL (from versions: )\u001b[0m\n",
            "\u001b[31mNo matching distribution found for PIL\u001b[0m\n",
            "Requirement already satisfied: image in /usr/local/lib/python3.6/dist-packages (1.5.27)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from image) (4.0.0)\n",
            "Requirement already satisfied: django in /usr/local/lib/python3.6/dist-packages (from image) (2.1.4)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow->image) (0.46)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from django->image) (2018.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iqGZzR8ejKxi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CdGO49KPosnC",
        "colab_type": "code",
        "outputId": "e584413a-1c7a-4564-a166-9d20c2e09552",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5933
        }
      },
      "cell_type": "code",
      "source": [
        "# Training our model\n",
        "\n",
        "import time\n",
        "\n",
        "t0 = time.time()\n",
        "\n",
        "n_epochs=40\n",
        "\n",
        "for epoch in range(1, n_epochs+1):\n",
        "  train_loss = 0.0\n",
        "  \n",
        "  for batch_i, (data, target) in enumerate(train_loader):\n",
        "    \n",
        "    \n",
        "    if torch.cuda.is_available():\n",
        "      data, target, model = data.cuda(), target.cuda(), model.cuda()\n",
        "    \n",
        "    \n",
        "    output = model(data)\n",
        "    loss = loss_fn(output, target)\n",
        "    train_loss +=loss.item()\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    if batch_i % 20 == 15:\n",
        "      print(\"Epoch: {}  Batch: {} loss: {}\".format(epoch, batch_i, train_loss/20))\n",
        "      train_loss = 0.0\n",
        "      model.eval()\n",
        "      total_correct = 0\n",
        "      total = 0\n",
        "      max_avg_output = torch.argmax(output, dim=1)\n",
        "      for number in range(len(data)):\n",
        "        correct = max_avg_output[number] == target[number]\n",
        "        total_correct += torch.Tensor.cpu(correct).numpy()\n",
        "        total += 1\n",
        "        \n",
        "      print('Correct: ', total_correct)\n",
        "      print('Total: ', total)\n",
        "      print('Training Accuracy: ', (total_correct/total))\n",
        "      model.train()\n",
        "      \n",
        "\n",
        "print(\"Total time it took: {} seconds\".format(time.time() - t0))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1  Batch: 15 loss: 3.6904879808425903\n",
            "Correct:  2\n",
            "Total:  100\n",
            "Training Accuracy:  0.02\n",
            "Epoch: 1  Batch: 35 loss: 4.595666551589966\n",
            "Correct:  1\n",
            "Total:  100\n",
            "Training Accuracy:  0.01\n",
            "Epoch: 1  Batch: 55 loss: 4.5586847305297855\n",
            "Correct:  2\n",
            "Total:  100\n",
            "Training Accuracy:  0.02\n",
            "Epoch: 2  Batch: 15 loss: 3.5798369646072388\n",
            "Correct:  3\n",
            "Total:  100\n",
            "Training Accuracy:  0.03\n",
            "Epoch: 2  Batch: 35 loss: 4.452191495895386\n",
            "Correct:  5\n",
            "Total:  100\n",
            "Training Accuracy:  0.05\n",
            "Epoch: 2  Batch: 55 loss: 4.423349022865295\n",
            "Correct:  9\n",
            "Total:  100\n",
            "Training Accuracy:  0.09\n",
            "Epoch: 3  Batch: 15 loss: 3.4575458765029907\n",
            "Correct:  5\n",
            "Total:  100\n",
            "Training Accuracy:  0.05\n",
            "Epoch: 3  Batch: 35 loss: 4.298711562156678\n",
            "Correct:  11\n",
            "Total:  100\n",
            "Training Accuracy:  0.11\n",
            "Epoch: 3  Batch: 55 loss: 4.221752285957336\n",
            "Correct:  11\n",
            "Total:  100\n",
            "Training Accuracy:  0.11\n",
            "Epoch: 4  Batch: 15 loss: 3.2598647475242615\n",
            "Correct:  16\n",
            "Total:  100\n",
            "Training Accuracy:  0.16\n",
            "Epoch: 4  Batch: 35 loss: 3.931946349143982\n",
            "Correct:  22\n",
            "Total:  100\n",
            "Training Accuracy:  0.22\n",
            "Epoch: 4  Batch: 55 loss: 3.83932079076767\n",
            "Correct:  22\n",
            "Total:  100\n",
            "Training Accuracy:  0.22\n",
            "Epoch: 5  Batch: 15 loss: 2.886331486701965\n",
            "Correct:  24\n",
            "Total:  100\n",
            "Training Accuracy:  0.24\n",
            "Epoch: 5  Batch: 35 loss: 3.4343915462493895\n",
            "Correct:  26\n",
            "Total:  100\n",
            "Training Accuracy:  0.26\n",
            "Epoch: 5  Batch: 55 loss: 3.3250973343849184\n",
            "Correct:  30\n",
            "Total:  100\n",
            "Training Accuracy:  0.3\n",
            "Epoch: 6  Batch: 15 loss: 2.457151913642883\n",
            "Correct:  31\n",
            "Total:  100\n",
            "Training Accuracy:  0.31\n",
            "Epoch: 6  Batch: 35 loss: 3.0042067885398867\n",
            "Correct:  28\n",
            "Total:  100\n",
            "Training Accuracy:  0.28\n",
            "Epoch: 6  Batch: 55 loss: 2.86188999414444\n",
            "Correct:  32\n",
            "Total:  100\n",
            "Training Accuracy:  0.32\n",
            "Epoch: 7  Batch: 15 loss: 2.1472380995750426\n",
            "Correct:  40\n",
            "Total:  100\n",
            "Training Accuracy:  0.4\n",
            "Epoch: 7  Batch: 35 loss: 2.5801950216293337\n",
            "Correct:  45\n",
            "Total:  100\n",
            "Training Accuracy:  0.45\n",
            "Epoch: 7  Batch: 55 loss: 2.4842196702957153\n",
            "Correct:  36\n",
            "Total:  100\n",
            "Training Accuracy:  0.36\n",
            "Epoch: 8  Batch: 15 loss: 1.9455854296684265\n",
            "Correct:  41\n",
            "Total:  100\n",
            "Training Accuracy:  0.41\n",
            "Epoch: 8  Batch: 35 loss: 2.3628743529319762\n",
            "Correct:  44\n",
            "Total:  100\n",
            "Training Accuracy:  0.44\n",
            "Epoch: 8  Batch: 55 loss: 2.2686016082763674\n",
            "Correct:  37\n",
            "Total:  100\n",
            "Training Accuracy:  0.37\n",
            "Epoch: 9  Batch: 15 loss: 1.7733668327331542\n",
            "Correct:  49\n",
            "Total:  100\n",
            "Training Accuracy:  0.49\n",
            "Epoch: 9  Batch: 35 loss: 2.1619426608085632\n",
            "Correct:  43\n",
            "Total:  100\n",
            "Training Accuracy:  0.43\n",
            "Epoch: 9  Batch: 55 loss: 2.10157310962677\n",
            "Correct:  53\n",
            "Total:  100\n",
            "Training Accuracy:  0.53\n",
            "Epoch: 10  Batch: 15 loss: 1.623158609867096\n",
            "Correct:  50\n",
            "Total:  100\n",
            "Training Accuracy:  0.5\n",
            "Epoch: 10  Batch: 35 loss: 2.0171971380710603\n",
            "Correct:  56\n",
            "Total:  100\n",
            "Training Accuracy:  0.56\n",
            "Epoch: 10  Batch: 55 loss: 1.9767959594726563\n",
            "Correct:  43\n",
            "Total:  100\n",
            "Training Accuracy:  0.43\n",
            "Epoch: 11  Batch: 15 loss: 1.5490744173526765\n",
            "Correct:  64\n",
            "Total:  100\n",
            "Training Accuracy:  0.64\n",
            "Epoch: 11  Batch: 35 loss: 1.8758602619171143\n",
            "Correct:  54\n",
            "Total:  100\n",
            "Training Accuracy:  0.54\n",
            "Epoch: 11  Batch: 55 loss: 1.8865937769412995\n",
            "Correct:  60\n",
            "Total:  100\n",
            "Training Accuracy:  0.6\n",
            "Epoch: 12  Batch: 15 loss: 1.4260874927043914\n",
            "Correct:  59\n",
            "Total:  100\n",
            "Training Accuracy:  0.59\n",
            "Epoch: 12  Batch: 35 loss: 1.8004624724388123\n",
            "Correct:  59\n",
            "Total:  100\n",
            "Training Accuracy:  0.59\n",
            "Epoch: 12  Batch: 55 loss: 1.7327438056468965\n",
            "Correct:  59\n",
            "Total:  100\n",
            "Training Accuracy:  0.59\n",
            "Epoch: 13  Batch: 15 loss: 1.3930480480194092\n",
            "Correct:  48\n",
            "Total:  100\n",
            "Training Accuracy:  0.48\n",
            "Epoch: 13  Batch: 35 loss: 1.6847402930259705\n",
            "Correct:  58\n",
            "Total:  100\n",
            "Training Accuracy:  0.58\n",
            "Epoch: 13  Batch: 55 loss: 1.6988515675067901\n",
            "Correct:  54\n",
            "Total:  100\n",
            "Training Accuracy:  0.54\n",
            "Epoch: 14  Batch: 15 loss: 1.3107705116271973\n",
            "Correct:  58\n",
            "Total:  100\n",
            "Training Accuracy:  0.58\n",
            "Epoch: 14  Batch: 35 loss: 1.5668696403503417\n",
            "Correct:  60\n",
            "Total:  100\n",
            "Training Accuracy:  0.6\n",
            "Epoch: 14  Batch: 55 loss: 1.5857715010643005\n",
            "Correct:  67\n",
            "Total:  100\n",
            "Training Accuracy:  0.67\n",
            "Epoch: 15  Batch: 15 loss: 1.24052751660347\n",
            "Correct:  58\n",
            "Total:  100\n",
            "Training Accuracy:  0.58\n",
            "Epoch: 15  Batch: 35 loss: 1.601420485973358\n",
            "Correct:  72\n",
            "Total:  100\n",
            "Training Accuracy:  0.72\n",
            "Epoch: 15  Batch: 55 loss: 1.4967629253864287\n",
            "Correct:  58\n",
            "Total:  100\n",
            "Training Accuracy:  0.58\n",
            "Epoch: 16  Batch: 15 loss: 1.1403380930423737\n",
            "Correct:  61\n",
            "Total:  100\n",
            "Training Accuracy:  0.61\n",
            "Epoch: 16  Batch: 35 loss: 1.4654926776885986\n",
            "Correct:  63\n",
            "Total:  100\n",
            "Training Accuracy:  0.63\n",
            "Epoch: 16  Batch: 55 loss: 1.4737578451633453\n",
            "Correct:  61\n",
            "Total:  100\n",
            "Training Accuracy:  0.61\n",
            "Epoch: 17  Batch: 15 loss: 1.1288950145244598\n",
            "Correct:  67\n",
            "Total:  100\n",
            "Training Accuracy:  0.67\n",
            "Epoch: 17  Batch: 35 loss: 1.469362872838974\n",
            "Correct:  58\n",
            "Total:  100\n",
            "Training Accuracy:  0.58\n",
            "Epoch: 17  Batch: 55 loss: 1.4114532828330995\n",
            "Correct:  68\n",
            "Total:  100\n",
            "Training Accuracy:  0.68\n",
            "Epoch: 18  Batch: 15 loss: 1.1205681204795837\n",
            "Correct:  59\n",
            "Total:  100\n",
            "Training Accuracy:  0.59\n",
            "Epoch: 18  Batch: 35 loss: 1.3787836611270905\n",
            "Correct:  61\n",
            "Total:  100\n",
            "Training Accuracy:  0.61\n",
            "Epoch: 18  Batch: 55 loss: 1.3461236596107482\n",
            "Correct:  59\n",
            "Total:  100\n",
            "Training Accuracy:  0.59\n",
            "Epoch: 19  Batch: 15 loss: 1.0952998042106628\n",
            "Correct:  68\n",
            "Total:  100\n",
            "Training Accuracy:  0.68\n",
            "Epoch: 19  Batch: 35 loss: 1.3320135116577148\n",
            "Correct:  70\n",
            "Total:  100\n",
            "Training Accuracy:  0.7\n",
            "Epoch: 19  Batch: 55 loss: 1.3465819180011749\n",
            "Correct:  66\n",
            "Total:  100\n",
            "Training Accuracy:  0.66\n",
            "Epoch: 20  Batch: 15 loss: 1.0288490176200866\n",
            "Correct:  62\n",
            "Total:  100\n",
            "Training Accuracy:  0.62\n",
            "Epoch: 20  Batch: 35 loss: 1.3020220816135406\n",
            "Correct:  66\n",
            "Total:  100\n",
            "Training Accuracy:  0.66\n",
            "Epoch: 20  Batch: 55 loss: 1.2938572227954865\n",
            "Correct:  65\n",
            "Total:  100\n",
            "Training Accuracy:  0.65\n",
            "Epoch: 21  Batch: 15 loss: 1.0315915286540984\n",
            "Correct:  66\n",
            "Total:  100\n",
            "Training Accuracy:  0.66\n",
            "Epoch: 21  Batch: 35 loss: 1.2518719375133514\n",
            "Correct:  58\n",
            "Total:  100\n",
            "Training Accuracy:  0.58\n",
            "Epoch: 21  Batch: 55 loss: 1.261802327632904\n",
            "Correct:  64\n",
            "Total:  100\n",
            "Training Accuracy:  0.64\n",
            "Epoch: 22  Batch: 15 loss: 0.9518524289131165\n",
            "Correct:  73\n",
            "Total:  100\n",
            "Training Accuracy:  0.73\n",
            "Epoch: 22  Batch: 35 loss: 1.2513375133275986\n",
            "Correct:  60\n",
            "Total:  100\n",
            "Training Accuracy:  0.6\n",
            "Epoch: 22  Batch: 55 loss: 1.2416326612234116\n",
            "Correct:  71\n",
            "Total:  100\n",
            "Training Accuracy:  0.71\n",
            "Epoch: 23  Batch: 15 loss: 0.9880354911088943\n",
            "Correct:  62\n",
            "Total:  100\n",
            "Training Accuracy:  0.62\n",
            "Epoch: 23  Batch: 35 loss: 1.233206072449684\n",
            "Correct:  64\n",
            "Total:  100\n",
            "Training Accuracy:  0.64\n",
            "Epoch: 23  Batch: 55 loss: 1.2018699109554292\n",
            "Correct:  63\n",
            "Total:  100\n",
            "Training Accuracy:  0.63\n",
            "Epoch: 24  Batch: 15 loss: 0.9401806682348252\n",
            "Correct:  78\n",
            "Total:  100\n",
            "Training Accuracy:  0.78\n",
            "Epoch: 24  Batch: 35 loss: 1.1639195799827575\n",
            "Correct:  77\n",
            "Total:  100\n",
            "Training Accuracy:  0.77\n",
            "Epoch: 24  Batch: 55 loss: 1.2388174116611481\n",
            "Correct:  66\n",
            "Total:  100\n",
            "Training Accuracy:  0.66\n",
            "Epoch: 25  Batch: 15 loss: 0.938002559542656\n",
            "Correct:  70\n",
            "Total:  100\n",
            "Training Accuracy:  0.7\n",
            "Epoch: 25  Batch: 35 loss: 1.1509810984134674\n",
            "Correct:  72\n",
            "Total:  100\n",
            "Training Accuracy:  0.72\n",
            "Epoch: 25  Batch: 55 loss: 1.0933619052171708\n",
            "Correct:  64\n",
            "Total:  100\n",
            "Training Accuracy:  0.64\n",
            "Epoch: 26  Batch: 15 loss: 0.9071598172187805\n",
            "Correct:  77\n",
            "Total:  100\n",
            "Training Accuracy:  0.77\n",
            "Epoch: 26  Batch: 35 loss: 1.1017613291740418\n",
            "Correct:  72\n",
            "Total:  100\n",
            "Training Accuracy:  0.72\n",
            "Epoch: 26  Batch: 55 loss: 1.116739884018898\n",
            "Correct:  69\n",
            "Total:  100\n",
            "Training Accuracy:  0.69\n",
            "Epoch: 27  Batch: 15 loss: 0.8743741780519485\n",
            "Correct:  72\n",
            "Total:  100\n",
            "Training Accuracy:  0.72\n",
            "Epoch: 27  Batch: 35 loss: 1.0545363068580627\n",
            "Correct:  73\n",
            "Total:  100\n",
            "Training Accuracy:  0.73\n",
            "Epoch: 27  Batch: 55 loss: 1.1331775397062303\n",
            "Correct:  67\n",
            "Total:  100\n",
            "Training Accuracy:  0.67\n",
            "Epoch: 28  Batch: 15 loss: 0.8732484638690948\n",
            "Correct:  78\n",
            "Total:  100\n",
            "Training Accuracy:  0.78\n",
            "Epoch: 28  Batch: 35 loss: 1.114883542060852\n",
            "Correct:  69\n",
            "Total:  100\n",
            "Training Accuracy:  0.69\n",
            "Epoch: 28  Batch: 55 loss: 1.083230698108673\n",
            "Correct:  70\n",
            "Total:  100\n",
            "Training Accuracy:  0.7\n",
            "Epoch: 29  Batch: 15 loss: 0.7995134055614471\n",
            "Correct:  78\n",
            "Total:  100\n",
            "Training Accuracy:  0.78\n",
            "Epoch: 29  Batch: 35 loss: 1.1119008928537368\n",
            "Correct:  68\n",
            "Total:  100\n",
            "Training Accuracy:  0.68\n",
            "Epoch: 29  Batch: 55 loss: 1.0517814189195633\n",
            "Correct:  70\n",
            "Total:  100\n",
            "Training Accuracy:  0.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wt5AaghOJtNi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'PyTorch_model.pt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KpJosHI8KA0q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}